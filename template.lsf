#BSUB -P csc499
#BSUB -W 0:60
#BSUB -nnodes TEMPLATE_NODES
#BSUB -q batch
#BSUB -J mldl_test_job
#BSUB -o job%J.out
#BSUB -e job%J.out
export NODES=$(cat ${LSB_DJOB_HOSTFILE} | sort | uniq | grep -v login | grep -v batch | wc -l)
export MASTER_ADDR=$(cat $LSB_DJOB_HOSTFILE | sort | uniq | grep -v batch | grep -v login | head -1)
export MASTER_PORT=23456
export OMP_NUM_THREADS=1
export NCCL_DEBUG=INFO
export GPUS_PER_NODE=TEMPLATE_GPUS_PER_NODE
export WORLD_SIZE=$((NODES*GPUS_PER_NODE))
export PYTHONPATH="$PYTHONPATH:$PWD/src"
jsrun -n${NODES} -a${GPUS_PER_NODE} -g${GPUS_PER_NODE} python -u src/training/benchmark.py TEMPLATE_EXTRA \
    --save-frequency 1 \
    --zeroshot-frequency 1 \
    --report-to tensorboard \
    --train-data="/gpfs/alpine/csc499/proj-shared/LAION-400m-webdataset/data/{00000..41455}.tar" \
    --bench-steps 1000 \
    --bench-warmup 10 \
    --batch-size=TEMPLATE_BATCH_SIZE \
    --workers=4 \
    --model TEMPLATE_MODEL \
    --dist-url="env://" \
    --name TEMPLATE_NAME \
    --logs TEMPLATE_LOGS \
    --local-loss \
    --gather-with-grad \
    --train-num-samples 407332084 \
    --grad-checkpointing
